{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de un modelo RAG con librerías Open Source\n",
    "\n",
    " - **Johan Sebastian Muñoz Ossa   --- js.munoz.ai@gmail.com  --- https://www.linkedin.com/in/js-munoz/**\n",
    "\n",
    "En este ejemplo se hace uso localmente de un LLM y una base de datos vectorial con librerías opensource como Ollama y Langchain. Luego de esto se contruye un Agente de tipo RAG simple, el cual permitira controlar el LLM para que responda información a partir de un PDF.\n",
    " \n",
    "# Requisitos\n",
    "\n",
    "* Tener instalado Ollama en local\n",
    "* Conexión a internet para instalar las demás librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://bookface-images.s3.amazonaws.com/logos/ee60f430e8cb6ae769306860a9c03b2672e0eaf2.png\" alt=\"Ollama Logo\" width=\"20%\">\n",
    "  <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2023/07/langchain3.png\" alt=\"Langchain Logo\" width=\"20%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install langchain\n",
    "!pip3 install langchain_pinecone\n",
    "!pip3 install langchain[docarray]\n",
    "!pip3 install docarray\n",
    "!pip3 install pypdf\n",
    "!pip3 install langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleccionar el LLM a usar\n",
    "\n",
    "Para esto, se necesita tener instalado el Ollama, Luego se ejecuta desde la aplicación o mediante terminal segun el modelo seleccionado, como por ejemplo para llama3:\n",
    "\n",
    "```\n",
    "\n",
    "ollama pull llama3\n",
    "\n",
    "```\n",
    "\n",
    "Los modelos disponibles en Ollama son: https://ollama.com/library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL = \"gpt-3.5-turbo\"\n",
    "#MODEL = \"mixtral:8x7b\"\n",
    "#MODEL = \"gemma:7b\"\n",
    "#MODEL = \"llama2\"\n",
    "MODEL = \"llama3.2\" # https://ollama.com/library/llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asociar el Modelo LLM con el Modelo de generación de embebddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola! Soy un modelo de lenguaje basado en inteligencia artificial, desarrollado por Meta AI. Me gusta llamarme \"Chatty\" (conversacional), ya que mi función es interactuar con usuarios y responder a sus preguntas y solicitudes de manera efectiva.\\n\\nMi capacidad para entender y generar texto me permite estar al día sobre una amplia variedad de temas, desde noticias y eventos actuales hasta información general y divertida. Me he entrenado en grandes cantidades de datos y tengo la capacidad de aprender y mejorar con cada conversación que tengo.\\n\\nSi tienes alguna pregunta o tema en particular que te gustaría discutir, estoy aquí para ayudarte!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "model = Ollama(model=MODEL)\n",
    "embeddings = OllamaEmbeddings(model=MODEL)\n",
    "\n",
    "model.invoke(\"Que modelo eres ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La respuesta es... 4!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"cuanto da 2+2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain permite usar un \"parser\" para que el texto se vea de una forma mas entendible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soy un modelo de lenguaje basado en inteligencia artificial desarrollado por Meta AI. Mi capacidad para entender y responder a preguntas, generar texto y realizar tareas de conversación se basa en algoritmos de aprendizaje automático y en grandes cantidades de datos.\n",
      "\n",
      "Mi estructura interna es similar a una red neuronal convolucional (CNN) que procesa entradas de texto y produce salidas de texto. Estoy capacitado para realizar various tareas, como:\n",
      "\n",
      "1. Entender y responder a preguntas.\n",
      "2. Generar texto sobre temas específicos.\n",
      "3. Realizar traducciones entre lenguajes.\n",
      "4. Responder a comentarios y mensajes.\n",
      "\n",
      "Estoy constantemente aprendiendo y mejorando gracias a la retroalimentación de los usuarios que interactúan conmigo, lo que me permite mejorar mi capacidad para comprender y responder a preguntas de manera efectiva.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "response_from_model = model.invoke(\"Que modelo eres ? \")\n",
    "parsed_response = parser.parse(response_from_model)\n",
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar una plantilla de conversación basada en instrucciones para el LLM\n",
    "\n",
    "Se crea una plantilla para tener una comunicación con el LLM efectiva, esta plantilla le entrega un contexto general al modelo, que sera utilizado en cada una de las preguntas que se le ingresen en adelante. En este punto del código es necesario usar todo el prompt engineering disponible para obtener las respuestas deseadas. \n",
    "\n",
    "La plantilla permite manipular una de las características que asegura las respuestas indicadas por parte del LLM. Adicionalmente se agrega un pequeño contexto, el cual le permite al LLM entender que debe responder en la pregunta que se le va a hacer.\n",
    "\n",
    "Esta estrategia brinda la posibilidad de tener controladas las respuestas del modelo, es decir, que trate de responder siempre con el contexto que se le fue dado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nResponde la pregunta basado en el contexto dado, Si no puedes responder la pregunta, genera la salida \"Lo siento, no puedo responder eso\"\\n\\nContext: Aca esta el contexto\\n\\nQuestion: Aca esta la pregunta\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "Responde la pregunta basado en el contexto dado, Si no puedes responder la pregunta, genera la salida \"Lo siento, no puedo responder eso\"\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Aca esta el contexto\", question=\"Aca esta la pregunta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 0}, page_content='MANAGEMENT SOLUTIONS El auge de los large language models: de los fundamentos a la aplicación  14LLM: definición, contexto y regulación\\n“Me dijeron que tendría un impacto positivo en el mundo. Nadie me preparó para la  \\ncantidad de preguntas ridículas que me harían a diario“.  \\nAnthropic Claude25'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 1}, page_content='15Definición  \\nLa inteligencia artificial generativa (GenAI) es un tipo de IA  \\ncapaz de generar diversos tipos de contenidos, como texto,  \\nimágenes, vídeos y audio. Utiliza modelos para aprender los  \\npatrones y la estructura de los datos de entrenamiento de  \\nentrada y, a continuación, genera nuevos contenidos basados  \\nen este conocimiento aprendido.  \\nDentro de la GenAI, los Large Language Models  (LLM) son, según  \\nla Comisión Europea, ”un tipo de modelo de inteligencia  \\nartificial que ha sido entrenado mediante algoritmos de  \\naprendizaje profundo para reconocer, generar, traducir y/o  \\nresumir grandes cantidades de lenguaje humano escrito y datos  \\ntextuales“26. \\nMuy comúnmente, estos modelos utilizan arquitecturas  \\nconocidas como transformers , que les permiten entender  \\ncontextos complejos y captar relaciones entre palabras  \\ndistantes en el texto. Entrenados con vastos conjuntos de datos,  \\ncomo libros, artículos y páginas web, los LLM aprenden  \\npatrones lingüísticos y estructuras para ejecutar tareas variadas,  \\nincluyendo generación de texto, traducción y análisis de  \\nsentimiento.  \\nLa eficacia de un LLM depende de su tamaño, la diversidad de  \\nlos datos de entrenamiento y la sofisticación de sus algoritmos,  \\nlo que influye directamente en su capacidad para aplicaciones  \\nprácticas en diversos campos. Por ello, entrenar un LLM es una  \\ntarea que requiere una capacidad muy elevada de computación  \\ny de tiempo de máquina, y por tanto costes muy significativos.  \\nComo referencia, según Sam Altman, entrenar GPT-4 costó ”más  \\nde 100 millones de dólares27. \\nEstos elevados costes hacen que el desarrollo de los mayores  \\nLLM esté concentrado en unas pocas organizaciones en el  \\nmundo (Fig. 4), con las capacidades tecnológicas, científicas y  \\nde inversión necesarias para abordar proyectos de esta  \\nenvergadura.  Evolución de los LLM  \\nEl desarrollo de los LLM representa una evolución sustancial  \\ndentro del campo del procesamiento de lenguaje natural (NLP),  \\ny se remonta al trabajo fundacional sobre semántica28 realizado  \\npor Michel Bréal en 1883. El advenimiento de los LLM comenzó  \\na mediados del siglo XX, precedido por sistemas que dependían  \\nen gran medida de reglas gramaticales creadas manualmente.  \\nUn caso emblemático de este período es el programa ”ELIZA“,  \\ncreado en 1966, que supuso un avance icónico en el desarrollo  \\nde modelos de lenguaje.  \\nA medida que el campo evolucionó, las décadas de 1980 y 1990  \\npresenciaron un cambio sustancial hacia métodos estadísticos  \\nde procesamiento de lenguaje. Este período vio la adopción de  \\nModelos Ocultos de Markov (HMMs) y modelos n-gram, que  \\nofrecieron un enfoque más dinámico para predecir secuencias  \\nde palabras basadas en probabilidades, en lugar de sistemas de  \\nreglas fijas.  \\nEl resurgimiento de las redes neuronales a principios de los años  \\n2000, gracias a los avances en algoritmos de retropropagación  \\nque mejoraron el entrenamiento de redes multicapa, marcó un  \\ndesarrollo crucial. Un hito fue la introducción de redes  \\nneuronales de alimentación directa para la modelización del  \\nlenguaje29 (Bengio et al., 2003). Esto sentó las bases para  \\ninnovaciones subsecuentes en la representación de palabras,  \\nespecialmente la introducción de embeddings  de palabras30 \\n(Mikolov et al., 2013) a través de Word2Vec. Los embeddings  \\nrepresentan palabras como vectores de números y permiten  \\n \\n25Claude (lanzado en 2023) es un modelo de lenguaje entrenado por Anthropic,  \\nuna startup  de IA fundada por Dario Amodei, Daniela Amodei, Tom Brown, Chris  \\nOlah, Sam McCandlish, Jack Clarke y Jared Kaplan en 2021. Claude fue diseñado  \\nusando la técnica de ”auto-aprendizaje alineado constitucionalmente“ de  \\nAnthropic, que se basa en proporcionar al modelo de un listado de principios y  \\nreglas para aumentar su seguridad y evitar comportamientos dañinos.  \\n26European Commission (2024).  \\n27Wired (2023).  \\n28Bréal (1883).  \\n29Bengio (2003).  \\n30Mikolov (2013).'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 2}, page_content='MANAGEMENT SOLUTIONS El auge de los large language models: de los fundamentos a la aplicación  16 \\n31Parikh, A. P. (2016).  \\n32Vaswani (2017).  \\n33Euronews (2023).  \\n34Adaptado de MindsDB (2024) y expandido.  definir distancias entre palabras, de manera que conceptos  \\nsimilares tengan distancias reducidas, y esto permite capturar  \\nrelaciones semánticas con una efectividad sin precedentes.   \\nLos primeros mecanismos de atención se introdujeron en  \\n201631, y permitieron resultados sin precedentes en tareas de  \\nprocesamiento del lenguaje, ya que identificaban la relevancia  \\nde diferentes partes del texto de entrada. Pero fue la  \\nintroducción de la arquitectura transformer32 (Vaswani et al.,  \\n2017) la que representó el verdadero cambio de paradigma en  \\nel entrenamiento de modelos y permitió la aparición de los LLM.  \\nEl núcleo de la innovación de los transformers  reside en los  \\nmecanismos de autoatención, que permiten a los modelos  \\nponderar la importancia relativa de diferentes palabras en una  \\noración. Esto significa que el modelo puede enfocarse en las  \\npartes más relevantes del texto al generar la respuesta, lo que es  \\ncrucial para analizar el contexto y las relaciones complejas  \\ndentro de las secuencias de palabras. Además, al habilitar el  \\nprocesamiento de datos de manera paralela, los transformers  \\nmejoran la eficiencia, la velocidad y el rendimiento del  \\nentrenamiento del modelo.  \\nLa serie de modelos GPT desarrollados por OpenAI,  \\ncomenzando con GPT-1 en junio de 2018 y llegando a GPT-4 en  \\nmarzo de 2023, ejemplifican los rápidos avances en las  \\ncapacidades de los LLM. En particular, GPT-3, lanzado en 2020  \\ncon 175.000 millones de parámetros, llegó al gran público y  mostró el extenso potencial de los LLM en diversas  \\naplicaciones. Además de la serie GPT de OpenAI, otros modelos  \\nde LLM como Google Gemini y Anthropic Claude han surgido  \\ncomo actores importantes en el panorama de la IA. Gemini es  \\nun ejemplo de cómo las grandes empresas tecnológicas están  \\ninvirtiendo en el desarrollo de LLM avanzados, mientras que  \\nClaude representa un esfuerzo por crear LLM que no solo sean  \\npotentes, sino también alineados con principios éticos y  \\nseguros para su uso.  \\nEl año 2023, llamado ”el año de la IA“33, destaca como un hito  \\nen la historia de los LLM, caracterizado por una mayor  \\naccesibilidad y contribuciones globales. Las innovaciones  \\ndurante este año demostraron que los LLM pueden construirse  \\ncon un mínimo de código, reduciendo significativamente las  \\nbarreras de entrada, aunque a la vez introduciendo nuevos  \\ndesafíos como el coste de entrenamiento y de inferencia, y sus  \\nriesgos inherentes. Este periodo también vio una preocupación  \\ncreciente por las consideraciones éticas y los desafíos  \\nFig. 4. Algunos de los principales LLM y sus proveedores34.\\nEmpresa LLM Comentarios País\\nOpenAI ChatGPT Conocido por su versatilidad en tareas lingüísticas, suele utilizarse para  \\ncompletar textos, traducir y mucho más.Estados Unidos\\nMicrosoft Orca Se centra en la creación de datos sintéticos y la mejora de las  \\ncapacidades de razonamiento.Estados Unidos\\nAnthropic Claude Reconocido por sus amplios conocimientos generales y su capacidad  \\nmultilingüe.Estados Unidos\\nGoogle Gemini, Gemma, BERT Pionero en el tratamiento del lenguaje con modelos que admiten  \\nmúltiples tipos de datos.Estados Unidos\\nMeta AI Llama Conocido por su eficacia y acceso democratizado, se centra en el alto  \\nrendimiento con un menor coste computacional.Estados Unidos\\nLMSYS Vicuna Perfeccionado para las funcionalidades de chatbot, ofrece un  \\ntratamiento único de las interacciones conversacionales.Estados Unidos\\nCohere Command-nightly Especializado en tiempos de respuesta rápidos y búsqueda semántica  \\nen más de 100 idiomas.Canadá\\nMistral AI Mistral, Mixtral Hace hincapié en modelos más pequeños pero potentes, que operan  \\nlocalmente con sólidas métricas de rendimiento.Francia'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 2}, page_content='en más de 100 idiomas.Canadá\\nMistral AI Mistral, Mixtral Hace hincapié en modelos más pequeños pero potentes, que operan  \\nlocalmente con sólidas métricas de rendimiento.Francia\\nClibrain LINCE Adaptado a la lengua española, centrado en los matices lingüísticos y  \\nla calidad de la comprensión.España\\nTechnology  \\nInnovation InstituteFalcon Proporciona modelos de IA de código abierto altamente eficientes y  \\nescalables con soporte multilingüe.Emiratos Árabes Unidos\\nAleph Alpha Luminous Destaca por su enfoque multimodal y su rendimiento competitivo en  \\ntareas básicas de IA.Alemania  \\nSenseTime SenseNova Una serie de modelos y aplicaciones de IA generativa que hacen uso  \\nde la plataforma de investigación y desarrollo AGI e integran LLM con  \\nsistemas informáticos a gran escala (SenseCore, con 5000 petaflops).Hong Kong'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 3}, page_content='17planteados por el desarrollo y el uso de los LLM y, como  \\nconsecuencia, un avance en la regulación de la IA y la IA  \\ngenerativa en todo el mundo.  \\nLa proliferación de los LLM de código abierto ha marcado un  \\nhito en la democratización de la tecnología de IA. Comenzando  \\npor Llama y siguiendo con Vicuna, Falcon, Mistral o Gemma,  \\nentre otros, los LLM open-source  han democratizado el acceso a  \\nla tecnología puntera en el procesamiento del lenguaje y han  \\npermitido a investigadores, desarrolladores y aficionados  \\nexperimentar, personalizar y desplegar soluciones de IA con  \\nuna inversión inicial mínima. La disponibilidad de estos  \\nmodelos ha fomentado una colaboración sin precedentes en la  \\ncomunidad de IA, estimulando la innovación y facilitando la  \\ncreación de aplicaciones avanzadas en una variedad de  \\nsectores.  \\nPor último, la integración de LLM en herramientas ofimáticas y  \\nde desarrollo de software está transformando la eficiencia y la  \\ncapacidad de las empresas. Microsoft ha integrado los LLM en  \\nsu suite de Office bajo el nombre de Microsoft 365 Copilot,  \\nmientras que Google lo ha hecho en Google Workspace. Al  \\nmismo tiempo, herramientas como GitHub Copilot o StarCoder  \\nutilizan LLM para asistir a los programadores, acelerando la  \\ngeneración de código y mejorando la calidad del desarrollo de  \\nsoftware.  Tipologías de LLM  \\nLos LLM han progresado más allá de la simple predicción de  \\ntexto y se han convertido en sofisticadas aplicaciones en  \\ndiversos dominios, arquitecturas y modalidades. Esta sección  \\npresenta una categorización de los LLM según varios criterios.  \\nPor arquitectura  \\n4 LLM basados en redes neuronales recurrentes (RNN):  \\nestos modelos procesan el texto secuencialmente,  \\nanalizando el impacto de cada palabra en la siguiente, y  \\nutilizan arquitecturas recurrentes, como memoria a largo  \\nplazo (LSTM) o unidades recurrentes de compuerta (GRU),  \\npara procesar datos secuenciales. Aunque no son tan  \\npotentes como los transformers  para secuencias largas, los  \\nRNN son útiles para tareas donde entender el orden de las  \\npalabras es crucial, como en la traducción automática. Son  \\nejemplos ELMo  (Embeddings from Language Models)  y \\nULMFiT (Universal Language Model Fine-tuning) . \\n4 LLM basados en  transformers: es la arquitectura  \\ndominante para los LLM hoy en día. Utilizan transformers  \\npara analizar las relaciones entre las palabras en una oración.  \\nEsto les permite capturar estructuras gramaticales complejas  \\ny dependencias entre palabras a gran distancia. La mayoría  \\nde los LLM, como GPT, Claude y Gemini, pertenecen a esta  \\ncategoría.  \\nPor componentes  \\n4 Codificadores (Encoders):  son modelos diseñados para  \\ncomprender (codificar) la información de entrada.  \\nTransforman el texto en una representación vectorial,  \\ncapturando su significado semántico. Los encoders  son  \\nfundamentales en tareas como la comprensión de texto y la'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 4}, page_content='MANAGEMENT SOLUTIONS El auge de los large language models: de los fundamentos a la aplicación  18clasificación. Un ejemplo es BERT, de Google, un modelo  \\nque analiza el contexto de cada palabra en un texto para  \\nentender su significado completo, y que no es realmente un  \\nLLM.  \\n4 Decodificadores  (Decoders):  estos modelos generan  \\n(decodifican) texto a partir de representaciones vectoriales.  \\nSon esenciales en la generación de texto, como en la  \\ncreación de contenido nuevo a partir de prompts  dados. La  \\nmayor parte de los LLM son decoders . \\n4 Codificadores/Decodificadores (Encoders/Decoders):  \\nestos modelos combinan encoders  y decoders  para convertir  \\nun tipo de información en otro, facilitando tareas como la  \\ntraducción automática, donde el texto de entrada se  \\ncodifica y luego se decodifica en otro idioma. Un ejemplo es  \\nT5 ( Text-to-Text Transfer Transformer ) de Google, diseñado  \\npara abordar múltiples tareas de procesamiento de lenguaje  \\nnatural.  \\nPor enfoque de entrenamiento  \\n4 LLM preentrenados: estos modelos se entrenan primero en  \\nun gran corpus de texto sin etiquetar utilizando técnicas de  \\naprendizaje autosupervisado como modelado de lenguaje  \\nenmascarado o predicción de la siguiente oración, y  \\ndespués se pueden ajustar con datos etiquetados más  \\npequeños para tareas específicas. Ejemplos de este tipo de  \\nLLM incluyen modelos como GPT, Mistral, BERT y RoBERTa,  \\nentre muchos otros.  \\n4 LLM específicos: estos modelos se entrenan desde cero con  \\ndatos etiquetados para una tarea particular, como análisis  \\nde sentimiento, resumen de textos o traducción automática.  \\nEjemplos de este tipo de LLM incluyen modelos de  \\ntraducción y resumen.  Por modalidad  \\n4 LLM de solo texto: son el tipo más común, entrenados y  \\ntrabajando exclusivamente con datos textuales. Son  \\nejemplos GPT-3, Mistral o Gemma.  \\n4 LLM multimodales: es un campo emergente donde los  \\nLLM son entrenados en una combinación de texto y otros  \\nformatos de datos como imágenes o audio. Esto les permite  \\nrealizar tareas que requieren entender la relación entre  \\ndiferentes modalidades. Son ejemplos GPT-4, Claude 3 y  \\nGemini.  \\nPor tamaño  \\n4 Large language models (LLM):  son modelos que utilizan  \\ncantidades masivas de parámetros. Son muy potentes, pero  \\nrequieren una infraestructura tecnológica en la nube,  \\nrelativamente costosa, para su ejecución. Son ejemplos  \\nGPT-4, Gemini o Claude 3.  \\n4 Small language models  (SLM): una tendencia reciente, los  \\nSLM son versiones más pequeñas y eficientes de los LLM,  \\ndiseñados para funcionar en dispositivos con recursos  \\nlimitados, como smartphones  o dispositivos IoT, sin  \\nnecesidad de conexión o despliegue en la nube. A pesar de  \\nsu tamaño reducido, estos modelos mantienen un  \\nrendimiento aceptable gracias a técnicas como la  \\ncompresión de modelos o la cuantización , que reduce la  \\nprecisión de los pesos y las activaciones del modelo. Son  \\nejemplos Gemini Nano de Google, o la familia de modelos  \\nPhi de Microsoft.'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 5}, page_content='LLM en la práctica: casos de uso en producción  \\n19A pesar del creciente interés y la exploración de posibles  \\naplicaciones de los LLM en las organizaciones, los casos de uso  \\nrealmente implementados en producción son aún limitados. La  \\nmayoría de las empresas se encuentran en etapas relativamente  \\ntempranas, identificando y priorizando potenciales casos de uso.  \\nNo obstante, varias compañías ya han logrado poner en  \\nproducción algunos casos de LLM, demostrando su valor tangible  \\npara el negocio y sus clientes. Aquí se resumen algunos de estos  \\ncasos:  \\n4Chatbots  internos:  bastantes organizaciones han  \\nimplementado chatbots  basados en LLM para facilitar el acceso  \\nde sus empleados a políticas, procedimientos e información  \\nrelevante de la compañía. Estos asistentes conversacionales  \\npermiten obtener respuestas rápidas y precisas a consultas  \\nfrecuentes, mejorando la eficiencia y reduciendo la carga sobre  \\notros canales de soporte interno.  \\n4Extracción de información:  los LLM están siendo utilizados  \\npara extraer automáticamente datos clave de documentos  \\nextensos y complejos, como memorias anuales o informes de  \\nriesgo climático. Estas herramientas son capaces de procesar  \\narchivos PDF de miles de páginas, con estructuras  \\nheterogéneas que incluyen imágenes, gráficos y tablas, y  \\ntransformar la información relevante en formatos  \\nestructurados y accesibles, como tablas ordenadas. Esta  \\nautomatización permite a las empresas ahorrar tiempo y  \\nrecursos en tareas de análisis documental.  \\n4Asistencia en centros de atención al cliente:  algunos contact  \\ncenters  están aprovechando los LLM para mejorar la calidad y  \\neficiencia del servicio. Aplicando técnicas de transcripción y  \\nresumen, estas herramientas generan un contexto de las  \\ninteracciones previas de cada cliente, permitiendo a los  \\nagentes ofrecer una atención más personalizada. Además,  \\ndurante las llamadas en curso, los LLM pueden proporcionar a  \\nlos agentes acceso en tiempo real a documentación relevante  \\npara responder las consultas específicas de los clientes, como  \\ninformación sobre comisiones bancarias o instrucciones para  \\nbloquear tarjetas de crédito.  4Clasificación inteligente de documentos:  las capacidades de  \\nprocesamiento de lenguaje natural de los LLM están siendo  \\naplicadas para clasificar automáticamente grandes volúmenes  \\nde documentos, como contratos o facturas, partiendo de su  \\ncontenido. Esta categorización inteligente permite a las  \\norganizaciones agilizar procesos de gestión documental y  \\nfacilita la búsqueda y recuperación de información relevante.  \\n4Banca conversacional:  algunos bancos están integrando LLM  \\nen sus aplicaciones móviles y canales digitales para ofrecer  \\nexperiencias conversacionales avanzadas a sus clientes. Estos  \\nchatbots son capaces de acceder a los datos transaccionales de  \\nlos usuarios en tiempo real y responder a consultas específicas,  \\ncomo «¿Cómo han sido mis gastos en el último mes?“ o  \\n«¿Cuánto he ganado en intereses por mis depósitos en el último  \\naño?“.  \\n4Asistencia en la redacción de informes de auditoría: las \\nfunciones de Auditoría Interna de algunas compañías ya están  \\nutilizando LLM para agilizar la elaboración de sus informes.  \\nEstas herramientas toman como inputs  los hallazgos del  \\nauditor, una base de datos con informes previos y otra con la  \\nnormativa aplicable, tanto interna como externa. A partir de  \\nesta información, los LLM generan un borrador avanzado del  \\ninforme de auditoría, adoptando el tono, vocabulario y estilo  \\nde los auditores, y citando adecuadamente informes anteriores  \\ny regulaciones relevantes. Esto permite a los auditores ahorrar  \\ntiempo significativo en tareas de redacción y centrarse en  \\nactividades de mayor valor añadido.  \\nEstos ejemplos ilustran cómo los LLM están creando valor real en  \\ndiversas funciones empresariales, desde la optimización de  \\nprocesos internos hasta la mejora de la experiencia del cliente. Si'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 5}, page_content='Estos ejemplos ilustran cómo los LLM están creando valor real en  \\ndiversas funciones empresariales, desde la optimización de  \\nprocesos internos hasta la mejora de la experiencia del cliente. Si  \\nbien actualmente el número de casos de uso en producción es  \\nlimitado, se espera que esta tendencia se acelere muy rápidamente  \\nen el futuro próximo, a medida que los LLM sigan evolucionando y  \\nse aborden de manera efectiva los desafíos relacionados con la  \\nprivacidad y la seguridad de los datos.'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 6}, page_content='MANAGEMENT SOLUTIONS El auge de los large language models: de los fundamentos a la aplicación  20Principales usos  \\nLos LLM están encontrando aplicaciones en una multitud de  \\ndominios, transformando sustancialmente la forma en que las  \\npersonas interactúan con la tecnología y aprovechado el  \\nprocesamiento de lenguaje natural para mejorar procesos,  \\nservicios y experiencias.  \\nA continuación, se resumen algunos de los usos más destacados  \\nde los LLM de texto.  \\n1. Creación y mejora de contenido  \\n4Generación de contenido: producción automática de  \\ntexto.  \\n4Asistencia de escritura: corrección ortotipográfica, de  \\nestilo y de contenido.  \\n4Traducción automática: conversión de texto de un  \\nidioma a otro.  \\n4Resumen de textos: reducción de documentos  \\nextensos a resúmenes.  \\n4Planificación y guion de contenidos: estructuración de  \\ncontenidos, p. ej., índices.  \\n4Brainstorming: propuestas creativas para proyectos,  \\nnombres, conceptos, etc.  \\n4Programación: creación de código de programación a  \\npartir de lenguaje natural.  \\n \\n2. Análisis y organización de información  \\n4Análisis de sentimientos: evaluación de emociones y  \\nopiniones en textos.  \\n4Extracción de información: extracción de datos  \\nespecíficos de documentos extensos.  \\n4Clasificación de textos: organización de textos en  \\ncategorías o temas específicos.  \\n4Revisión técnica: asistencia en revisar documentos  \\nespecializados (p. ej., legales).  \\n 3. Interacción y automatización  \\n4Chatbots: simulación de conversaciones sobre temas  \\ngenerales o específicos.  \\n4Q&A: generación de respuestas a preguntas basadas  \\nen un corpus.  \\n \\nEstos usos resumen las aplicaciones actuales de los LLM de  \\ntexto. Con la emergencia de los LLM multimodales, comienzan  \\na aflorar aplicaciones adicionales como la generación de  \\ncontenido audiovisual, la interpretación de datos a partir de  \\nimágenes, la traducción de contenido multimedia o la creación  \\nde experiencias interactivas enriquecidas, como la interacción  \\ncon chatbots  con entradas no solo de texto, sino también de  \\nimagen, audio y vídeo.  \\nRequisitos regulatorios  \\nLa rápida evolución de la inteligencia artificial generativa,  \\nespecialmente en el campo de los modelos de lenguaje de gran  \\nescala (LLM), ha captado la atención de reguladores a nivel  \\nglobal. El potencial de estos sistemas para influir de forma  \\nnegativa en los ciudadanos ha llevado a un incremento en las  \\niniciativas para establecer marcos regulatorios que aseguren su  \\ndesarrollo y uso responsable.  \\nAlgunas de las principales iniciativas regulatorias sobre IA son:  \\n4 El AI Act de la Unión Europea: propuesta legislativa  \\npionera para regular la IA, que clasifica los sistemas de IA  \\nsegún su nivel de riesgo y establece requisitos de  \\ntransparencia, seguridad y derechos fundamentales. El AI  \\nAct fue aprobado por el Parlamento Europeo el 13 de marzo  \\nde 2024.  \\n4 El AI Bill of Rights de Estados Unidos:  documento  \\norientativo que busca proteger los derechos civiles en el  \\ndesarrollo y aplicación de la IA, enfatizando la privacidad, la  \\nno discriminación y la transparencia.  \\n4 La guía sobre IA del NIST35 de Estados Unidos: establece  \\nprincipios para la creación de sistemas de IA fiables, con  \\nenfoque en la precisión, la explicabilidad y la mitigación de  \\nsesgos.  \\n \\n35El Instituto Nacional de Estándares y Tecnología (NIST) ha publicado  \\ndocumentos que detallan marcos de ciberseguridad, de gestión de riesgos y,  \\nconcretamente, de gestión de modelos de IA y de IA generativa.'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 7}, page_content='21 \\n37IAPP (2024).  \\n 4 La Declaración de Bletchley: compromiso internacional  \\npara el desarrollo responsable de la IA, promoviendo  \\nprincipios de transparencia, seguridad y equidad, firmado  \\npor múltiples países.  \\nAdemás de las iniciativas mencionadas, numerosos países han  \\ncomenzado a emitir sus propias regulaciones locales o han  \\nestablecido principios para la adopción de la IA de manera ética  \\ny segura. Entre ellos se cuentan36 Reino Unido, Francia, España,  \\nAlemania, Países Bajos, Polonia, Australia, Nueva Zelanda,  \\nSingapur, Canadá, Japón, Corea del Sur, China, India, Indonesia,  \\nIsrael, Emiratos Árabes Unidos, Arabia Saudí, Egipto, Brasil, Chile,  \\nPerú, Argentina, México, Colombia y Turquía, entre otros.  \\nTodas estas iniciativas regulatorias plantean requisitos muy  \\nsimilares sobre la IA que, aplicados a los LLM, se pueden resumir  \\nen: \\n4 Transparencia y explicabilidad: obligación de revelar  \\ncómo funciona el LLM, incluyendo la lógica detrás de sus  \\nsalidas para que sean comprensibles para los usuarios.  \\n4 Privacidad y protección de datos: medidas estrictas para  \\nproteger la información personal recopilada o generada por  \\nLLM, cumpliendo con leyes de protección de datos, como  \\nGDPR en Europa.  \\n4 Equidad y no discriminación:  requisitos para prevenir  \\nsesgos y asegurar que los LLM no perpetúen  \\ndiscriminaciones ni prejuicios, mediante la evaluación y  \\ncorrección constantes de sus algoritmos.  4 Seguridad y fiabilidad: exigencias de robustez operacional  \\npara prevenir disfunciones o manipulaciones que puedan  \\ncausar daño o pérdida de información.  \\n4 Responsabilidad y gobernanza: marco de responsabilidad  \\nde desarrolladores y usuarios de LLM en caso de daños o  \\nviolaciones de derechos, incluyendo mecanismos de  \\nsupervisión y control.  \\n4 Supervisión humana: la necesidad de mantener una  \\nsupervisión humana efectiva sobre los LLM, asegurando que  \\nlas decisiones importantes puedan ser revisadas y, si es  \\nnecesario, corregidas o revertidas por humanos.  \\nEstos requisitos reflejan un consenso emergente sobre los  \\nprincipios fundamentales para el desarrollo ético y seguro de los  \\nLLM, y forman la base para futuras regulaciones específicas y  \\nadaptaciones según evolucione la tecnología.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Libreria de Langchain que permite extraer información de documentos y cargarla en memoria\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(r\"auge-de-los-llm-03.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "#pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "División del PDF cargado, en lotes pequeños de información. Esto permite manipular mas facil la información y realizar una busqueda mas acertada de un dato en específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 0}, page_content='MANAGEMENT SOLUTIONS El auge de los large language models: de los fundamentos a la aplicación  14LLM: definición, contexto y regulación\\n“Me dijeron que tendría un impacto positivo en el mundo. Nadie me preparó para la  \\ncantidad de preguntas ridículas que me harían a diario“.  \\nAnthropic Claude25'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 1}, page_content='15Definición  \\nLa inteligencia artificial generativa (GenAI) es un tipo de IA  \\ncapaz de generar diversos tipos de contenidos, como texto,  \\nimágenes, vídeos y audio. Utiliza modelos para aprender los  \\npatrones y la estructura de los datos de entrenamiento de  \\nentrada y, a continuación, genera nuevos contenidos basados  \\nen este conocimiento aprendido.  \\nDentro de la GenAI, los Large Language Models  (LLM) son, según  \\nla Comisión Europea, ”un tipo de modelo de inteligencia  \\nartificial que ha sido entrenado mediante algoritmos de  \\naprendizaje profundo para reconocer, generar, traducir y/o  \\nresumir grandes cantidades de lenguaje humano escrito y datos  \\ntextuales“26. \\nMuy comúnmente, estos modelos utilizan arquitecturas  \\nconocidas como transformers , que les permiten entender  \\ncontextos complejos y captar relaciones entre palabras  \\ndistantes en el texto. Entrenados con vastos conjuntos de datos,  \\ncomo libros, artículos y páginas web, los LLM aprenden  \\npatrones lingüísticos y estructuras para ejecutar tareas variadas,  \\nincluyendo generación de texto, traducción y análisis de  \\nsentimiento.  \\nLa eficacia de un LLM depende de su tamaño, la diversidad de  \\nlos datos de entrenamiento y la sofisticación de sus algoritmos,  \\nlo que influye directamente en su capacidad para aplicaciones  \\nprácticas en diversos campos. Por ello, entrenar un LLM es una  \\ntarea que requiere una capacidad muy elevada de computación  \\ny de tiempo de máquina, y por tanto costes muy significativos.  \\nComo referencia, según Sam Altman, entrenar GPT-4 costó ”más  \\nde 100 millones de dólares27. \\nEstos elevados costes hacen que el desarrollo de los mayores  \\nLLM esté concentrado en unas pocas organizaciones en el  \\nmundo (Fig. 4), con las capacidades tecnológicas, científicas y  \\nde inversión necesarias para abordar proyectos de esta  \\nenvergadura.  Evolución de los LLM  \\nEl desarrollo de los LLM representa una evolución sustancial  \\ndentro del campo del procesamiento de lenguaje natural (NLP),  \\ny se remonta al trabajo fundacional sobre semántica28 realizado  \\npor Michel Bréal en 1883. El advenimiento de los LLM comenzó  \\na mediados del siglo XX, precedido por sistemas que dependían  \\nen gran medida de reglas gramaticales creadas manualmente.  \\nUn caso emblemático de este período es el programa ”ELIZA“,  \\ncreado en 1966, que supuso un avance icónico en el desarrollo  \\nde modelos de lenguaje.  \\nA medida que el campo evolucionó, las décadas de 1980 y 1990  \\npresenciaron un cambio sustancial hacia métodos estadísticos  \\nde procesamiento de lenguaje. Este período vio la adopción de  \\nModelos Ocultos de Markov (HMMs) y modelos n-gram, que  \\nofrecieron un enfoque más dinámico para predecir secuencias  \\nde palabras basadas en probabilidades, en lugar de sistemas de  \\nreglas fijas.  \\nEl resurgimiento de las redes neuronales a principios de los años  \\n2000, gracias a los avances en algoritmos de retropropagación  \\nque mejoraron el entrenamiento de redes multicapa, marcó un  \\ndesarrollo crucial. Un hito fue la introducción de redes  \\nneuronales de alimentación directa para la modelización del  \\nlenguaje29 (Bengio et al., 2003). Esto sentó las bases para  \\ninnovaciones subsecuentes en la representación de palabras,  \\nespecialmente la introducción de embeddings  de palabras30 \\n(Mikolov et al., 2013) a través de Word2Vec. Los embeddings  \\nrepresentan palabras como vectores de números y permiten  \\n \\n25Claude (lanzado en 2023) es un modelo de lenguaje entrenado por Anthropic,  \\nuna startup  de IA fundada por Dario Amodei, Daniela Amodei, Tom Brown, Chris  \\nOlah, Sam McCandlish, Jack Clarke y Jared Kaplan en 2021. Claude fue diseñado  \\nusando la técnica de ”auto-aprendizaje alineado constitucionalmente“ de  \\nAnthropic, que se basa en proporcionar al modelo de un listado de principios y  \\nreglas para aumentar su seguridad y evitar comportamientos dañinos.  \\n26European Commission (2024).  \\n27Wired (2023).  \\n28Bréal (1883).  \\n29Bengio (2003).  \\n30Mikolov (2013).'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 2}, page_content='MANAGEMENT SOLUTIONS El auge de los large language models: de los fundamentos a la aplicación  16 \\n31Parikh, A. P. (2016).  \\n32Vaswani (2017).  \\n33Euronews (2023).  \\n34Adaptado de MindsDB (2024) y expandido.  definir distancias entre palabras, de manera que conceptos  \\nsimilares tengan distancias reducidas, y esto permite capturar  \\nrelaciones semánticas con una efectividad sin precedentes.   \\nLos primeros mecanismos de atención se introdujeron en  \\n201631, y permitieron resultados sin precedentes en tareas de  \\nprocesamiento del lenguaje, ya que identificaban la relevancia  \\nde diferentes partes del texto de entrada. Pero fue la  \\nintroducción de la arquitectura transformer32 (Vaswani et al.,  \\n2017) la que representó el verdadero cambio de paradigma en  \\nel entrenamiento de modelos y permitió la aparición de los LLM.  \\nEl núcleo de la innovación de los transformers  reside en los  \\nmecanismos de autoatención, que permiten a los modelos  \\nponderar la importancia relativa de diferentes palabras en una  \\noración. Esto significa que el modelo puede enfocarse en las  \\npartes más relevantes del texto al generar la respuesta, lo que es  \\ncrucial para analizar el contexto y las relaciones complejas  \\ndentro de las secuencias de palabras. Además, al habilitar el  \\nprocesamiento de datos de manera paralela, los transformers  \\nmejoran la eficiencia, la velocidad y el rendimiento del  \\nentrenamiento del modelo.  \\nLa serie de modelos GPT desarrollados por OpenAI,  \\ncomenzando con GPT-1 en junio de 2018 y llegando a GPT-4 en  \\nmarzo de 2023, ejemplifican los rápidos avances en las  \\ncapacidades de los LLM. En particular, GPT-3, lanzado en 2020  \\ncon 175.000 millones de parámetros, llegó al gran público y  mostró el extenso potencial de los LLM en diversas  \\naplicaciones. Además de la serie GPT de OpenAI, otros modelos  \\nde LLM como Google Gemini y Anthropic Claude han surgido  \\ncomo actores importantes en el panorama de la IA. Gemini es  \\nun ejemplo de cómo las grandes empresas tecnológicas están  \\ninvirtiendo en el desarrollo de LLM avanzados, mientras que  \\nClaude representa un esfuerzo por crear LLM que no solo sean  \\npotentes, sino también alineados con principios éticos y  \\nseguros para su uso.  \\nEl año 2023, llamado ”el año de la IA“33, destaca como un hito  \\nen la historia de los LLM, caracterizado por una mayor  \\naccesibilidad y contribuciones globales. Las innovaciones  \\ndurante este año demostraron que los LLM pueden construirse  \\ncon un mínimo de código, reduciendo significativamente las  \\nbarreras de entrada, aunque a la vez introduciendo nuevos  \\ndesafíos como el coste de entrenamiento y de inferencia, y sus  \\nriesgos inherentes. Este periodo también vio una preocupación  \\ncreciente por las consideraciones éticas y los desafíos  \\nFig. 4. Algunos de los principales LLM y sus proveedores34.\\nEmpresa LLM Comentarios País\\nOpenAI ChatGPT Conocido por su versatilidad en tareas lingüísticas, suele utilizarse para  \\ncompletar textos, traducir y mucho más.Estados Unidos\\nMicrosoft Orca Se centra en la creación de datos sintéticos y la mejora de las  \\ncapacidades de razonamiento.Estados Unidos\\nAnthropic Claude Reconocido por sus amplios conocimientos generales y su capacidad  \\nmultilingüe.Estados Unidos\\nGoogle Gemini, Gemma, BERT Pionero en el tratamiento del lenguaje con modelos que admiten  \\nmúltiples tipos de datos.Estados Unidos\\nMeta AI Llama Conocido por su eficacia y acceso democratizado, se centra en el alto  \\nrendimiento con un menor coste computacional.Estados Unidos\\nLMSYS Vicuna Perfeccionado para las funcionalidades de chatbot, ofrece un  \\ntratamiento único de las interacciones conversacionales.Estados Unidos\\nCohere Command-nightly Especializado en tiempos de respuesta rápidos y búsqueda semántica  \\nen más de 100 idiomas.Canadá\\nMistral AI Mistral, Mixtral Hace hincapié en modelos más pequeños pero potentes, que operan  \\nlocalmente con sólidas métricas de rendimiento.Francia'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 2}, page_content='en más de 100 idiomas.Canadá\\nMistral AI Mistral, Mixtral Hace hincapié en modelos más pequeños pero potentes, que operan  \\nlocalmente con sólidas métricas de rendimiento.Francia\\nClibrain LINCE Adaptado a la lengua española, centrado en los matices lingüísticos y  \\nla calidad de la comprensión.España\\nTechnology  \\nInnovation InstituteFalcon Proporciona modelos de IA de código abierto altamente eficientes y  \\nescalables con soporte multilingüe.Emiratos Árabes Unidos\\nAleph Alpha Luminous Destaca por su enfoque multimodal y su rendimiento competitivo en  \\ntareas básicas de IA.Alemania  \\nSenseTime SenseNova Una serie de modelos y aplicaciones de IA generativa que hacen uso  \\nde la plataforma de investigación y desarrollo AGI e integran LLM con  \\nsistemas informáticos a gran escala (SenseCore, con 5000 petaflops).Hong Kong'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 3}, page_content='17planteados por el desarrollo y el uso de los LLM y, como  \\nconsecuencia, un avance en la regulación de la IA y la IA  \\ngenerativa en todo el mundo.  \\nLa proliferación de los LLM de código abierto ha marcado un  \\nhito en la democratización de la tecnología de IA. Comenzando  \\npor Llama y siguiendo con Vicuna, Falcon, Mistral o Gemma,  \\nentre otros, los LLM open-source  han democratizado el acceso a  \\nla tecnología puntera en el procesamiento del lenguaje y han  \\npermitido a investigadores, desarrolladores y aficionados  \\nexperimentar, personalizar y desplegar soluciones de IA con  \\nuna inversión inicial mínima. La disponibilidad de estos  \\nmodelos ha fomentado una colaboración sin precedentes en la  \\ncomunidad de IA, estimulando la innovación y facilitando la  \\ncreación de aplicaciones avanzadas en una variedad de  \\nsectores.  \\nPor último, la integración de LLM en herramientas ofimáticas y  \\nde desarrollo de software está transformando la eficiencia y la  \\ncapacidad de las empresas. Microsoft ha integrado los LLM en  \\nsu suite de Office bajo el nombre de Microsoft 365 Copilot,  \\nmientras que Google lo ha hecho en Google Workspace. Al  \\nmismo tiempo, herramientas como GitHub Copilot o StarCoder  \\nutilizan LLM para asistir a los programadores, acelerando la  \\ngeneración de código y mejorando la calidad del desarrollo de  \\nsoftware.  Tipologías de LLM  \\nLos LLM han progresado más allá de la simple predicción de  \\ntexto y se han convertido en sofisticadas aplicaciones en  \\ndiversos dominios, arquitecturas y modalidades. Esta sección  \\npresenta una categorización de los LLM según varios criterios.  \\nPor arquitectura  \\n4 LLM basados en redes neuronales recurrentes (RNN):  \\nestos modelos procesan el texto secuencialmente,  \\nanalizando el impacto de cada palabra en la siguiente, y  \\nutilizan arquitecturas recurrentes, como memoria a largo  \\nplazo (LSTM) o unidades recurrentes de compuerta (GRU),  \\npara procesar datos secuenciales. Aunque no son tan  \\npotentes como los transformers  para secuencias largas, los  \\nRNN son útiles para tareas donde entender el orden de las  \\npalabras es crucial, como en la traducción automática. Son  \\nejemplos ELMo  (Embeddings from Language Models)  y \\nULMFiT (Universal Language Model Fine-tuning) . \\n4 LLM basados en  transformers: es la arquitectura  \\ndominante para los LLM hoy en día. Utilizan transformers  \\npara analizar las relaciones entre las palabras en una oración.  \\nEsto les permite capturar estructuras gramaticales complejas  \\ny dependencias entre palabras a gran distancia. La mayoría  \\nde los LLM, como GPT, Claude y Gemini, pertenecen a esta  \\ncategoría.  \\nPor componentes  \\n4 Codificadores (Encoders):  son modelos diseñados para  \\ncomprender (codificar) la información de entrada.  \\nTransforman el texto en una representación vectorial,  \\ncapturando su significado semántico. Los encoders  son  \\nfundamentales en tareas como la comprensión de texto y la'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 4}, page_content='MANAGEMENT SOLUTIONS El auge de los large language models: de los fundamentos a la aplicación  18clasificación. Un ejemplo es BERT, de Google, un modelo  \\nque analiza el contexto de cada palabra en un texto para  \\nentender su significado completo, y que no es realmente un  \\nLLM.  \\n4 Decodificadores  (Decoders):  estos modelos generan  \\n(decodifican) texto a partir de representaciones vectoriales.  \\nSon esenciales en la generación de texto, como en la  \\ncreación de contenido nuevo a partir de prompts  dados. La  \\nmayor parte de los LLM son decoders . \\n4 Codificadores/Decodificadores (Encoders/Decoders):  \\nestos modelos combinan encoders  y decoders  para convertir  \\nun tipo de información en otro, facilitando tareas como la  \\ntraducción automática, donde el texto de entrada se  \\ncodifica y luego se decodifica en otro idioma. Un ejemplo es  \\nT5 ( Text-to-Text Transfer Transformer ) de Google, diseñado  \\npara abordar múltiples tareas de procesamiento de lenguaje  \\nnatural.  \\nPor enfoque de entrenamiento  \\n4 LLM preentrenados: estos modelos se entrenan primero en  \\nun gran corpus de texto sin etiquetar utilizando técnicas de  \\naprendizaje autosupervisado como modelado de lenguaje  \\nenmascarado o predicción de la siguiente oración, y  \\ndespués se pueden ajustar con datos etiquetados más  \\npequeños para tareas específicas. Ejemplos de este tipo de  \\nLLM incluyen modelos como GPT, Mistral, BERT y RoBERTa,  \\nentre muchos otros.  \\n4 LLM específicos: estos modelos se entrenan desde cero con  \\ndatos etiquetados para una tarea particular, como análisis  \\nde sentimiento, resumen de textos o traducción automática.  \\nEjemplos de este tipo de LLM incluyen modelos de  \\ntraducción y resumen.  Por modalidad  \\n4 LLM de solo texto: son el tipo más común, entrenados y  \\ntrabajando exclusivamente con datos textuales. Son  \\nejemplos GPT-3, Mistral o Gemma.  \\n4 LLM multimodales: es un campo emergente donde los  \\nLLM son entrenados en una combinación de texto y otros  \\nformatos de datos como imágenes o audio. Esto les permite  \\nrealizar tareas que requieren entender la relación entre  \\ndiferentes modalidades. Son ejemplos GPT-4, Claude 3 y  \\nGemini.  \\nPor tamaño  \\n4 Large language models (LLM):  son modelos que utilizan  \\ncantidades masivas de parámetros. Son muy potentes, pero  \\nrequieren una infraestructura tecnológica en la nube,  \\nrelativamente costosa, para su ejecución. Son ejemplos  \\nGPT-4, Gemini o Claude 3.  \\n4 Small language models  (SLM): una tendencia reciente, los  \\nSLM son versiones más pequeñas y eficientes de los LLM,  \\ndiseñados para funcionar en dispositivos con recursos  \\nlimitados, como smartphones  o dispositivos IoT, sin  \\nnecesidad de conexión o despliegue en la nube. A pesar de  \\nsu tamaño reducido, estos modelos mantienen un  \\nrendimiento aceptable gracias a técnicas como la  \\ncompresión de modelos o la cuantización , que reduce la  \\nprecisión de los pesos y las activaciones del modelo. Son  \\nejemplos Gemini Nano de Google, o la familia de modelos  \\nPhi de Microsoft.'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 5}, page_content='LLM en la práctica: casos de uso en producción  \\n19A pesar del creciente interés y la exploración de posibles  \\naplicaciones de los LLM en las organizaciones, los casos de uso  \\nrealmente implementados en producción son aún limitados. La  \\nmayoría de las empresas se encuentran en etapas relativamente  \\ntempranas, identificando y priorizando potenciales casos de uso.  \\nNo obstante, varias compañías ya han logrado poner en  \\nproducción algunos casos de LLM, demostrando su valor tangible  \\npara el negocio y sus clientes. Aquí se resumen algunos de estos  \\ncasos:  \\n4Chatbots  internos:  bastantes organizaciones han  \\nimplementado chatbots  basados en LLM para facilitar el acceso  \\nde sus empleados a políticas, procedimientos e información  \\nrelevante de la compañía. Estos asistentes conversacionales  \\npermiten obtener respuestas rápidas y precisas a consultas  \\nfrecuentes, mejorando la eficiencia y reduciendo la carga sobre  \\notros canales de soporte interno.  \\n4Extracción de información:  los LLM están siendo utilizados  \\npara extraer automáticamente datos clave de documentos  \\nextensos y complejos, como memorias anuales o informes de  \\nriesgo climático. Estas herramientas son capaces de procesar  \\narchivos PDF de miles de páginas, con estructuras  \\nheterogéneas que incluyen imágenes, gráficos y tablas, y  \\ntransformar la información relevante en formatos  \\nestructurados y accesibles, como tablas ordenadas. Esta  \\nautomatización permite a las empresas ahorrar tiempo y  \\nrecursos en tareas de análisis documental.  \\n4Asistencia en centros de atención al cliente:  algunos contact  \\ncenters  están aprovechando los LLM para mejorar la calidad y  \\neficiencia del servicio. Aplicando técnicas de transcripción y  \\nresumen, estas herramientas generan un contexto de las  \\ninteracciones previas de cada cliente, permitiendo a los  \\nagentes ofrecer una atención más personalizada. Además,  \\ndurante las llamadas en curso, los LLM pueden proporcionar a  \\nlos agentes acceso en tiempo real a documentación relevante  \\npara responder las consultas específicas de los clientes, como  \\ninformación sobre comisiones bancarias o instrucciones para  \\nbloquear tarjetas de crédito.  4Clasificación inteligente de documentos:  las capacidades de  \\nprocesamiento de lenguaje natural de los LLM están siendo  \\naplicadas para clasificar automáticamente grandes volúmenes  \\nde documentos, como contratos o facturas, partiendo de su  \\ncontenido. Esta categorización inteligente permite a las  \\norganizaciones agilizar procesos de gestión documental y  \\nfacilita la búsqueda y recuperación de información relevante.  \\n4Banca conversacional:  algunos bancos están integrando LLM  \\nen sus aplicaciones móviles y canales digitales para ofrecer  \\nexperiencias conversacionales avanzadas a sus clientes. Estos  \\nchatbots son capaces de acceder a los datos transaccionales de  \\nlos usuarios en tiempo real y responder a consultas específicas,  \\ncomo «¿Cómo han sido mis gastos en el último mes?“ o  \\n«¿Cuánto he ganado en intereses por mis depósitos en el último  \\naño?“.  \\n4Asistencia en la redacción de informes de auditoría: las \\nfunciones de Auditoría Interna de algunas compañías ya están  \\nutilizando LLM para agilizar la elaboración de sus informes.  \\nEstas herramientas toman como inputs  los hallazgos del  \\nauditor, una base de datos con informes previos y otra con la  \\nnormativa aplicable, tanto interna como externa. A partir de  \\nesta información, los LLM generan un borrador avanzado del  \\ninforme de auditoría, adoptando el tono, vocabulario y estilo  \\nde los auditores, y citando adecuadamente informes anteriores  \\ny regulaciones relevantes. Esto permite a los auditores ahorrar  \\ntiempo significativo en tareas de redacción y centrarse en  \\nactividades de mayor valor añadido.  \\nEstos ejemplos ilustran cómo los LLM están creando valor real en  \\ndiversas funciones empresariales, desde la optimización de  \\nprocesos internos hasta la mejora de la experiencia del cliente. Si'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 5}, page_content='Estos ejemplos ilustran cómo los LLM están creando valor real en  \\ndiversas funciones empresariales, desde la optimización de  \\nprocesos internos hasta la mejora de la experiencia del cliente. Si  \\nbien actualmente el número de casos de uso en producción es  \\nlimitado, se espera que esta tendencia se acelere muy rápidamente  \\nen el futuro próximo, a medida que los LLM sigan evolucionando y  \\nse aborden de manera efectiva los desafíos relacionados con la  \\nprivacidad y la seguridad de los datos.'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 6}, page_content='MANAGEMENT SOLUTIONS El auge de los large language models: de los fundamentos a la aplicación  20Principales usos  \\nLos LLM están encontrando aplicaciones en una multitud de  \\ndominios, transformando sustancialmente la forma en que las  \\npersonas interactúan con la tecnología y aprovechado el  \\nprocesamiento de lenguaje natural para mejorar procesos,  \\nservicios y experiencias.  \\nA continuación, se resumen algunos de los usos más destacados  \\nde los LLM de texto.  \\n1. Creación y mejora de contenido  \\n4Generación de contenido: producción automática de  \\ntexto.  \\n4Asistencia de escritura: corrección ortotipográfica, de  \\nestilo y de contenido.  \\n4Traducción automática: conversión de texto de un  \\nidioma a otro.  \\n4Resumen de textos: reducción de documentos  \\nextensos a resúmenes.  \\n4Planificación y guion de contenidos: estructuración de  \\ncontenidos, p. ej., índices.  \\n4Brainstorming: propuestas creativas para proyectos,  \\nnombres, conceptos, etc.  \\n4Programación: creación de código de programación a  \\npartir de lenguaje natural.  \\n \\n2. Análisis y organización de información  \\n4Análisis de sentimientos: evaluación de emociones y  \\nopiniones en textos.  \\n4Extracción de información: extracción de datos  \\nespecíficos de documentos extensos.  \\n4Clasificación de textos: organización de textos en  \\ncategorías o temas específicos.  \\n4Revisión técnica: asistencia en revisar documentos  \\nespecializados (p. ej., legales).  \\n 3. Interacción y automatización  \\n4Chatbots: simulación de conversaciones sobre temas  \\ngenerales o específicos.  \\n4Q&A: generación de respuestas a preguntas basadas  \\nen un corpus.  \\n \\nEstos usos resumen las aplicaciones actuales de los LLM de  \\ntexto. Con la emergencia de los LLM multimodales, comienzan  \\na aflorar aplicaciones adicionales como la generación de  \\ncontenido audiovisual, la interpretación de datos a partir de  \\nimágenes, la traducción de contenido multimedia o la creación  \\nde experiencias interactivas enriquecidas, como la interacción  \\ncon chatbots  con entradas no solo de texto, sino también de  \\nimagen, audio y vídeo.  \\nRequisitos regulatorios  \\nLa rápida evolución de la inteligencia artificial generativa,  \\nespecialmente en el campo de los modelos de lenguaje de gran  \\nescala (LLM), ha captado la atención de reguladores a nivel  \\nglobal. El potencial de estos sistemas para influir de forma  \\nnegativa en los ciudadanos ha llevado a un incremento en las  \\niniciativas para establecer marcos regulatorios que aseguren su  \\ndesarrollo y uso responsable.  \\nAlgunas de las principales iniciativas regulatorias sobre IA son:  \\n4 El AI Act de la Unión Europea: propuesta legislativa  \\npionera para regular la IA, que clasifica los sistemas de IA  \\nsegún su nivel de riesgo y establece requisitos de  \\ntransparencia, seguridad y derechos fundamentales. El AI  \\nAct fue aprobado por el Parlamento Europeo el 13 de marzo  \\nde 2024.  \\n4 El AI Bill of Rights de Estados Unidos:  documento  \\norientativo que busca proteger los derechos civiles en el  \\ndesarrollo y aplicación de la IA, enfatizando la privacidad, la  \\nno discriminación y la transparencia.  \\n4 La guía sobre IA del NIST35 de Estados Unidos: establece  \\nprincipios para la creación de sistemas de IA fiables, con  \\nenfoque en la precisión, la explicabilidad y la mitigación de  \\nsesgos.  \\n \\n35El Instituto Nacional de Estándares y Tecnología (NIST) ha publicado  \\ndocumentos que detallan marcos de ciberseguridad, de gestión de riesgos y,  \\nconcretamente, de gestión de modelos de IA y de IA generativa.'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 7}, page_content='21 \\n37IAPP (2024).  \\n 4 La Declaración de Bletchley: compromiso internacional  \\npara el desarrollo responsable de la IA, promoviendo  \\nprincipios de transparencia, seguridad y equidad, firmado  \\npor múltiples países.  \\nAdemás de las iniciativas mencionadas, numerosos países han  \\ncomenzado a emitir sus propias regulaciones locales o han  \\nestablecido principios para la adopción de la IA de manera ética  \\ny segura. Entre ellos se cuentan36 Reino Unido, Francia, España,  \\nAlemania, Países Bajos, Polonia, Australia, Nueva Zelanda,  \\nSingapur, Canadá, Japón, Corea del Sur, China, India, Indonesia,  \\nIsrael, Emiratos Árabes Unidos, Arabia Saudí, Egipto, Brasil, Chile,  \\nPerú, Argentina, México, Colombia y Turquía, entre otros.  \\nTodas estas iniciativas regulatorias plantean requisitos muy  \\nsimilares sobre la IA que, aplicados a los LLM, se pueden resumir  \\nen: \\n4 Transparencia y explicabilidad: obligación de revelar  \\ncómo funciona el LLM, incluyendo la lógica detrás de sus  \\nsalidas para que sean comprensibles para los usuarios.  \\n4 Privacidad y protección de datos: medidas estrictas para  \\nproteger la información personal recopilada o generada por  \\nLLM, cumpliendo con leyes de protección de datos, como  \\nGDPR en Europa.  \\n4 Equidad y no discriminación:  requisitos para prevenir  \\nsesgos y asegurar que los LLM no perpetúen  \\ndiscriminaciones ni prejuicios, mediante la evaluación y  \\ncorrección constantes de sus algoritmos.  4 Seguridad y fiabilidad: exigencias de robustez operacional  \\npara prevenir disfunciones o manipulaciones que puedan  \\ncausar daño o pérdida de información.  \\n4 Responsabilidad y gobernanza: marco de responsabilidad  \\nde desarrolladores y usuarios de LLM en caso de daños o  \\nviolaciones de derechos, incluyendo mecanismos de  \\nsupervisión y control.  \\n4 Supervisión humana: la necesidad de mantener una  \\nsupervisión humana efectiva sobre los LLM, asegurando que  \\nlas decisiones importantes puedan ser revisadas y, si es  \\nnecesario, corregidas o revertidas por humanos.  \\nEstos requisitos reflejan un consenso emergente sobre los  \\nprincipios fundamentales para el desarrollo ético y seguro de los  \\nLLM, y forman la base para futuras regulaciones específicas y  \\nadaptaciones según evolucione la tecnología.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "text_documents = text_splitter.split_documents(pages)[:-1]\n",
    "\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar la información obtenida del PDF en un espacio vectorial.\n",
    "\n",
    "Desde la documentación de Langchain:\n",
    "\n",
    "`DocArrayInMemorySearch is a document index provided by Docarray that stores documents in memory. It is a great starting point for small datasets, where you may not want to launch a database server.`\n",
    "\n",
    "El tiempo de ejecución de esta celda depende de los recursos computacionales del equipo y de que tan largo sea el PDF ingresado. **Si se quiere llevar a una aplicacion real, es necesario el uso de una base de datos robusta que permita la búsqueda vectorial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Langchain/lib/python3.12/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(text_documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear un recuperador de vectores similares para usarlos como contexto\n",
    "\n",
    "La mayoría de recuperadores de vectores, hacen uso de otros algoritmos de machine learning, para agrupar y encontrar un conjunto de vectores que sean similares al vector creado cuando se le hace la pregunta al agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 2}, page_content='multilingüe.Estados Unidos\\nGoogle Gemini, Gemma, BERT Pionero en el tratamiento del lenguaje con modelos que admiten  \\nmúltiples tipos de datos.Estados Unidos\\nMeta AI Llama Conocido por su eficacia y acceso democratizado, se centra en el alto  \\nrendimiento con un menor coste computacional.Estados Unidos\\nLMSYS Vicuna Perfeccionado para las funcionalidades de chatbot, ofrece un  \\ntratamiento único de las interacciones conversacionales.Estados Unidos'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 2}, page_content='dentro de las secuencias de palabras. Además, al habilitar el  \\nprocesamiento de datos de manera paralela, los transformers  \\nmejoran la eficiencia, la velocidad y el rendimiento del  \\nentrenamiento del modelo.  \\nLa serie de modelos GPT desarrollados por OpenAI,  \\ncomenzando con GPT-1 en junio de 2018 y llegando a GPT-4 en  \\nmarzo de 2023, ejemplifican los rápidos avances en las  \\ncapacidades de los LLM. En particular, GPT-3, lanzado en 2020'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 1}, page_content='2000, gracias a los avances en algoritmos de retropropagación  \\nque mejoraron el entrenamiento de redes multicapa, marcó un  \\ndesarrollo crucial. Un hito fue la introducción de redes  \\nneuronales de alimentación directa para la modelización del  \\nlenguaje29 (Bengio et al., 2003). Esto sentó las bases para  \\ninnovaciones subsecuentes en la representación de palabras,  \\nespecialmente la introducción de embeddings  de palabras30 \\n(Mikolov et al., 2013) a través de Word2Vec. Los embeddings'),\n",
       " Document(metadata={'source': 'auge-de-los-llm-03.pdf', 'page': 5}, page_content='utilizando LLM para agilizar la elaboración de sus informes.  \\nEstas herramientas toman como inputs  los hallazgos del  \\nauditor, una base de datos con informes previos y otra con la  \\nnormativa aplicable, tanto interna como externa. A partir de  \\nesta información, los LLM generan un borrador avanzado del  \\ninforme de auditoría, adoptando el tono, vocabulario y estilo  \\nde los auditores, y citando adecuadamente informes anteriores')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retrieved_context = retriever.invoke(\"Generative AI, que es un LLM, que es GPT\")\n",
    "\n",
    "retrieved_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactuando con el agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Que es un LLM\n",
      "Answer: Basándome en el contexto dado, puedo responder que un LLM (Large Language Model) se refiere a modelos de lenguaje grandes que admiten múltiples tipos de datos. Estos modelos están diseñados para el tratamiento del lenguaje y mejoran la eficiencia, velocidad y rendimiento del entrenamiento del modelo al habilitar el procesamiento de datos de manera paralela.\n",
      "\n",
      "Question: Que es la Inteligencia Artificial Generativa\n",
      "Answer: La pregunta se refiere a la Inteligencia Artificial (IA) generativa, que se describe en el contexto dado como una serie de modelos desarrollados por OpenAI, comenzando con GPT-1 en junio de 2018 y llegando a GPT-4 en marzo de 2023. Estos modelos, conocidos como Generative Pre-trained Transformers (GPT), están diseñados para el procesamiento del lenguaje natural y pueden generar texto basado en secuencias de palabras.\n",
      "\n",
      "Por lo tanto, la respuesta es:\n",
      "\n",
      "La Inteligencia Artificial Generativa se refiere a una serie de modelos desarrollados por OpenAI, conocidos como GPT, que están diseñados para el procesamiento del lenguaje natural y pueden generar texto basado en secuencias de palabras.\n",
      "\n",
      "Question: Que es GPT\n",
      "Answer: Basándome en el contexto dado, puedo responder que GPT (Generative Pre-trained Transformer) es una serie de modelos desarrollados por OpenAI, empezando con GPT-1 en junio de 2018 y llegando a GPT-4 en marzo de 2023.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Que es un LLM\",\n",
    "    \"Que es la Inteligencia Artificial Generativa\",\n",
    "    \"Que es GPT\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    formatted_prompt = prompt.format(context=retrieved_context, question=question)\n",
    "    response_from_model = model.invoke(formatted_prompt)\n",
    "    parsed_response = parser.parse(response_from_model)\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {parsed_response}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
